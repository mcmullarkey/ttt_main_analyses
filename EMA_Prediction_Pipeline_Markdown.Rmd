---
title: "Practicing_EMA_Prediction_Pipeline"
author: "Michael Mullarkey"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    toc: yes
    toc_depth: 5
    toc_float:
      collapsed: no
      smooth_scroll: no
geometry: margin=0.50in
---

```{r setup, include=FALSE, cache = FALSE}
require("knitr")
## setting working directory
knitr::opts_chunk$set(echo = TRUE, tidy = TRUE, warning = FALSE, message = FALSE, include = FALSE)
```

```{r}

## Need to load tensorflow into r (since it's a dependency for the embed package with the umap non-linear dimensionality reduction) before we point to the Python environment

# library(tensorflow)
# tensorflow::install_tensorflow()

## Setting up pyton within Rstudio

## Using these steps https://support.rstudio.com/hc/en-us/articles/360023654474-Installing-and-Configuring-Python-with-RStudio

## For step 2 I used to use conda to make sure I used a later Python off the system path as outlined here, but that caused more headaches so I just follow all steps outlined in the website above instead. https://support.rstudio.com/hc/en-us/articles/360022909454-Best-Practices-for-Using-Python-with-RStudio-Connect

## Here's a video that also walks through the process https://docs.rstudio.com/tutorials/user/using-python-with-rstudio-and-reticulate/

if(!require(reticulate)){install.packages('reticulate')}
library(reticulate)

# Only run this once to create the environment
# conda_create("ttt-reticulate-yml", environment = "ttt_conda_environment.yml")

use_condaenv("ttt-reticulate-yml")

py_config()

# To use for embed package, though mgiht not be necessary

# library(tensorflow)
# tensorflow::install_tensorflow(method = "conda")


```

```{python}

# Checking Python is working within RStudio

1 + 1

```


```{r loading packages}

if(!require(tidymodels)){install.packages('tidymodels')}
library(tidymodels)
if(!require(tidyverse)){install.packages('tidyverse')}
library(tidyverse)
if(!require(skimr)){install.packages('skimr')}
library(skimr)
if(!require(furrr)){install.packages('furrr')}
library(furrr)
if(!require(tictoc)){install.packages('tictoc')}
library(tictoc)
if(!require(heatmaply)){install.packages('heatmaply')}
library(heatmaply)
if(!require(doMC)){install.packages('doMC')}
library(doMC)
if(!require(glue)){install.packages('glue')}
library(glue)
if(!require(stacks)){install.packages('stacks')}
library(stacks)
if(!require(janitor)){install.packages('janitor')}
library(janitor)
if(!require(future)){install.packages('future')}
library(future)
if(!require(reticulate)){install.packages('reticulate')}
library(reticulate)
if(!require(psych)){install.packages('psych')}
library(psych)
if(!require(imputeTS)){install.packages('imputeTS')}
library(imputeTS)
if(!require(timetk)){install.packages('timetk')}
library(timetk)
if(!require(tidyquant)){install.packages('tidyquant')}
library(tidyquant)
if(!require(tsibble)){install.packages('tsibble')}
library(tsibble)
if(!require(feasts)){install.packages('feasts')}
library(feasts)
if(!require(dtw)){install.packages('dtw')}
library(dtw)
if(!require(parallelDist)){install.packages('parallelDist')}
library(parallelDist)
if(!require(pheatmap)){install.packages('pheatmap')}
library(pheatmap)
if(!require(diffdf)){install.packages('diffdf')}
library(diffdf)
# if(!require(tensorflow)){install.packages('tensorflow')}
# library(tensorflow)
# if(!require(keras)){install.packages('keras')}
# library(keras)
# if(!require(embed)){install.packages('embed')}
# library(embed)
if(!require(lubridate)){install.packages('lubridate')}
library(lubridate)
if(!require(ggdist)){install.packages('ggdist')}
library(ggdist)
if(!require(gt)){install.packages('gt')}
library(gt)
if(!require(broom)){install.packages('broom')}
library(broom)
if(!require(glmnet)){install.packages('glmnet')}
library(glmnet)
if(!require(xgboost)){install.packages('xgboost')}
library(xgboost)

## Let's set our number of cores for this document (May differ across computers)

registerDoMC(cores = 7)

```

## Reading in the Data

```{r reading in pre post data}

## Reading in pre/post data for the college students

pre_post_data <- read_csv("cleaned_qualtrics_ttt_phase_1.csv") %>% 
  clean_names() %>% 
  mutate(yb_dep_diff = resid(lm(sum_y3m_cdi~sum_yb_cdi, data = cur_data(), na.action = na.exclude)))

```

```{r}

pre_post_data

```


```{r reading in ema data}

## Reading in EMA data

ema_data_init <- read_csv("cleaned_lifepak_ttt_phase_1.csv") %>% 
  clean_names()

```

```{r}

# check to see if anyone doesn't have enough data to even approximate a series

too_few_sessions <- ema_data_init %>% 
  count(lifepak_id) %>% 
  filter(n <= 4) %>% 
  print()

## Let's keep everyone with at least half the days (we only lose one person this way)

ema_data_sec <- ema_data_init %>% 
  filter(!lifepak_id %in% too_few_sessions$lifepak_id)

# Confirm they've been dropped

ema_data_sec %>% 
  count(lifepak_id) %>% 
  filter(n <= 4)

```

```{r}

## does anyone have more than 5 observations for any given day?
too_many_obs <- ema_data_sec %>% 
  mutate(day = day(notification_time)) %>% 
  count(lifepak_id, day) %>% 
  filter(n > 5)

## Taking the first response of the two in this case (You could average, but only accepting the first one as valid seems more in line with the data generating process for the other responses, though that's a subjective call)

ema_data_extra <- ema_data_sec %>% 
  mutate(day = day(notification_time)) %>%
  group_by(lifepak_id, day) %>%
  mutate(row = row_number()) %>% 
  filter(row <= 5) %>%
  dplyr::select(-row) %>% 
  ungroup()

# Confirming the later row was dropped for that participant and no one else has more than 5 observations in a day

ema_data_extra %>% 
  count(lifepak_id, day) %>% 
  filter(n > 5)
  
```

# Joining Youth Pre/3 Month CDI to LifePak Data 

```{r}

cdi_data_init <- ema_data_extra %>% 
  left_join(pre_post_data %>% select(yb_life_pak_id, yb_dep_diff), by = c("lifepak_id" = "yb_life_pak_id")) %>% 
  mutate(lifepak_id_int = as.integer(lifepak_id))

```
# Looking at How Frequently Sessions Were Completed

```{r}

cdi_data_init %>% 
  group_by(lifepak_id) %>% 
  count(completed_session) %>% 
  filter(completed_session == 1) %>% 
  ungroup() %>% 
  summarize(avg_completed = mean(n), sd_completed = sd(n))

```
# Descriptive Statistics Grouped by Person

```{r}

# cdi_data_init %>% 
#   group_by(lifepak_id) %>% 
#   summarize(mean = mean(bad, na.rm = TRUE), sd = sd(bad, na.rm = TRUE)) %>% 
#   mutate(sd_range = if_else(sd < 15, "SD < 15", "SD > 15")) %>% 
#   ggplot(aes(x = lifepak_id, ydist = "norm", arg1 = mean, arg2 = sd)) +
#   stat_halfeye(position = "dodge") +
#   theme_minimal() +
#   theme(axis.text.x = element_blank()) +
#   ylim(0, 100) +
#   facet_wrap(~sd_range)
  

```

```{r}

# cdi_data_init %>% 
#   group_by(lifepak_id) %>% 
#   summarize(mean = mean(bad, na.rm = TRUE), sd = sd(bad, na.rm = TRUE)) %>% 
#   mutate(sd_range = case_when(
#     sd < 10 ~ "SD < 10", 
#     sd >= 10 & sd < 20 ~"20 > SD > 10",
#     sd >= 20 ~ "SD > 20"
#     )
# ) %>% 
#   ggplot(aes(x = lifepak_id, ydist = distributional::dist_normal(mean, sd))) +
#   stat_halfeye(position = "dodge") +
#   theme_minimal() +
#   theme(axis.text.x = element_blank()) +
#   ylim(0, 100) +
#   facet_wrap(~sd_range)

```
## Plotting Raw Data for Bad by Participant

We can use this as a figure in the main text to illustrate how the distributions are different across participants.

```{r}

cdi_data_init %>% 
  ggplot(aes(x = sad, color = sad)) +
  geom_dots(alpha = 0.6) +
  scale_color_distiller(type = "seq",
                        direction = -1,
                        palette = "Greys") +
  theme_minimal() +
  theme(legend.position = "none",
        plot.title.position = "plot",
        axis.text.y = element_blank(),
        axis.text.x = element_blank()) +
  facet_wrap(~lifepak_id) +
  labs(title = "Distributions of 'Sad' EMA Ratings Grouped by Participant",
    subtitle = "Minimum X-Axis Value is 0 and Maximum X-Axis Value is 100",
    x = "")

ggsave('sad_distribution.jpg')

```

## Creating Table of Summary Statistics for EMA Data by Participant

This table can be part of the supplement.

```{r}

cdi_data_init %>% 
   group_by(lifepak_id) %>% 
   summarize(
     across(
       c(bad,control:movement, sad),
       list(mean = "mean", sd = "sd"),
       na.rm = TRUE,
       .names = "{.col}_{.fn}"
     )
   ) %>% 
  gt(rowname_col = "lifepak_id") %>% 
  tab_stubhead(label = "ID") %>% 
  fmt_number(columns = where(is.numeric),
             decimals = 2) %>% 
  cols_label(bad_mean = "Mean",
             bad_sd = "SD",
             control_mean = "Mean",
             control_sd = "SD",
             energy_mean = "Mean",
             energy_sd = "SD",
             focus_mean = "Mean",
             focus_sd = "SD",
             fun_mean = "Mean",
             fun_sd = "SD",
             interest_mean = "Mean",
             interest_sd = "SD",
             movement_mean = "Mean",
             movement_sd = "SD",
             sad_mean = "Mean",
             sad_sd = "SD") %>% 
  tab_spanner(label = "Bad",
              columns = c(bad_mean, bad_sd)) %>% 
  tab_spanner(label = "Control",
              columns = c(control_mean, control_sd)) %>% 
  tab_spanner(label = "Energy",
              columns = c(energy_mean, energy_sd)) %>% 
  tab_spanner(label = "Focus",
              columns = c(focus_mean, focus_sd)) %>% 
  tab_spanner(label = "Fun",
              columns = c(fun_mean, fun_sd)) %>% 
  tab_spanner(label = "Interest",
              columns = c(interest_mean, interest_sd)) %>% 
  tab_spanner(label = "Movement",
              columns = c(movement_mean, movement_sd)) %>% 
  tab_spanner(label = "Sad",
              columns = c(sad_mean, sad_sd))

```

```{r nesting the ema data for wide format and rsample breaking things up into training and testing}

## Nesting the data so the ema data can be included within a wide format (Helps us break up into training/testing + create custom recipe steps)

nested_ema_data <- cdi_data_init %>% 
  group_by(lifepak_id, yb_dep_diff) %>%
  nest() %>% 
  filter(!is.na(yb_dep_diff)) %>% 
  dplyr::rename(ema_data = data)

## Break into training/testing data

set.seed(33)
# Put 1/2 of the data into the training set, stratify based on the ts_diff outcome 
nested_ema_split <- initial_split(nested_ema_data, prop = 4/5, strata = yb_dep_diff)

# Create data frames for the two sets:
train_nested_ema <- training(nested_ema_split)
test_nested_ema  <- testing(nested_ema_split)

```

```{r creating long form training and testing data}

train_long_ema <- cdi_data_init %>% 
  dplyr::select(lifepak_id:response_no, c(bad, control:movement, sad),lifepak_id_int) %>% 
  filter(lifepak_id %in% train_nested_ema$lifepak_id) %>% 
  dplyr::select(-lifepak_id) %>% 
  group_by(lifepak_id_int) %>% 
  complete(response_no = 1:107) %>%
  dplyr::mutate(across(where(is.numeric), ~na_interpolation(.x, option = "spline")
  ),
  response_no = as.integer(response_no)) %>%
  ungroup() %>% 
  print()

# train_long_ema_data_ts_fresh <- train_long_ema %>% 
#   dplyr::select(-contains("dep"))

train_outcome_wide <- train_nested_ema %>% 
  unnest() %>% 
  distinct(lifepak_id, .keep_all = T) %>% 
  ungroup() %>% 
  dplyr::select(yb_dep_diff)

test_long_ema <- cdi_data_init %>% 
  dplyr::select(lifepak_id:response_no, c(bad, control:movement, sad),lifepak_id_int) %>% 
  filter(lifepak_id %in% train_nested_ema$lifepak_id) %>% 
  dplyr::select(-lifepak_id) %>% 
  group_by(lifepak_id_int) %>% 
  complete(response_no = 1:107) %>%
  dplyr::mutate(across(where(is.numeric), ~na_interpolation(.x, option = "spline")
  ),
  response_no = as.integer(response_no)) %>%
  ungroup() %>% 
  print()

## Creating the number of cores to use in parallel for tsfresh (Only using physical cores with logical = FALSE)

cores <- detectCores(logical = FALSE) - 1L

```

```{python trying to run tsfresh on the long training data}

## Using https://tsfresh.readthedocs.io/en/latest/text/quick_start.html
## If I try to impute/filter I end up with a different number of rows, so that's not super helpful. Might be names collisons with the example I loaded earlier or something else about how I'm running the Python code I don't understand yet

## Use this page as a guideline for switching back and forth between Pyton and R within RStudio/RMarkdown https://rstudio.github.io/reticulate/articles/r_markdown.html

## Example from the docs works https://tsfresh.readthedocs.io/en/latest/text/quick_start.html

# from tsfresh.examples.robot_execution_failures import download_robot_execution_failures,load_robot_execution_failures
# download_robot_execution_failures()
# timeseries, y = load_robot_execution_failures()
# 
# print(timeseries)
# 
# type(timeseries)
# 
# timeseries.dtypes
# 
from tsfresh import extract_features
# extracted_features = extract_features(timeseries, column_id="id", column_sort="time")

## Trying to apply that to our data

print(r.train_long_ema) # Looks similar as the timeseries data

type(r.train_long_ema) # Has same type as timeseries

r.train_long_ema.dtypes # If we read in this data with the depression outcome as a boolean (which shouldn't be in the data at all) tsfresh won't work

r.train_long_ema.dtypes # So we read in the updated data without the depression outcome as boolean

extracted_features_r = extract_features(r.train_long_ema, column_id="lifepak_id_int", column_sort="response_no")

```

```{r looking at the tsfresh object}

## A function for selecting non-na values

not_all_na <- function(x) {!all(is.na(x))}

# A funciton for selecting non all 0 values

not_all_zero <- function(x) {!all(x == 0)}

tic()
ts_fresh_features <- as_tibble(py$extracted_features_r) %>% 
  clean_names() %>% 
  select_if(not_all_na) %>% 
  select_if(not_all_zero)
toc()

# glimpse(ts_fresh_features) 

ts_fresh_id <- ts_fresh_features %>% 
  bind_cols(train_nested_ema %>% ungroup() %>% dplyr::select(lifepak_id)) %>% 
  relocate(lifepak_id, everything())
  

```

```{r writing a function to create dynamic time warp features}

## Need this function for imputation

## Creating function to do necessary imputation

tidy_imputation <- function(.data){

  tidyverse_lags_test <- .data %>%
  dplyr::select(-c(response_no, lifepak_id_int)) %>%
  dplyr::mutate(across(where(is.numeric), ~na_interpolation(.x, option = "spline")
  ))

}

## See this blog post https://eiko-fried.com/modeling-idiographic-and-nomothetic-dynamics-of-255-depressed-inpatients/ and this paper https://bmcmedicine.biomedcentral.com/articles/10.1186/s12916-020-01867-5
## Also this code https://eiko-fried.com/wp-content/uploads/Code-Hebbrecht-et-al-2020-dtw.txt

## Creating function to generate Dynamic Time Warp distance values for each pair of time series within each person

creating_dtw_distances <- function(.data){

  row_names <- .data %>% 
    dplyr::select(-lifepak_id_int) %>% 
    names()
  column_names <- .data %>% 
    dplyr::select(-lifepak_id_int) %>% 
    names()
  
  distance <- parDist(.data %>% dplyr::select(-lifepak_id_int) %>%  as.matrix(), method = "dtw", 
    window.type = "sakoechiba", window.size = 2, step.pattern = "symmetricP0")
  
  distance <- as.matrix(distance)
  distance <- distance[c(1:8),c(1:8)]
  
  colnames(distance) <- column_names
  
  distance <- as_tibble(distance) %>% 
    mutate(var_names = row_names) %>% 
    relocate(var_names, everything())
}

# heatmap_ema <- function(dist){
#     pheatmap(dist %>% as.matrix(), 
#          display_numbers = TRUE, border_color = FALSE, 
#          clustering_method = "ward.D2", treeheight_row = 0, 
#          treeheight_col = 0, color = colorRampPalette(brewer.pal(n = 7, name = "RdYlBu"))(100), 
#          number_format = "%.0f", legend = FALSE)
# }
# 
# heatmap_ema(distance)

## Creating function to pivot the DTW results wider to create the features + renaming them using the names we dynamically generated

pivoting_dtw_results_wider <- function(.data){
.data %>% 
  as_tibble() %>% 
  pivot_wider(
    names_from = var_names,
    values_from = c(bad:sad)
  )
}

## Creating duplicate names for DTW features to help remove them from the feature set later (Since they're all 0)

exclude_dtw_same_var_features <- function(.data){
  
  ready_for_dup_name <- .data %>% 
    dplyr::select(where(is.numeric)) %>% 
    names()

dupe_df <- enframe(ready_for_dup_name) %>% 
  mutate(first = word(value, 1, sep = "_"),
         second = word(value, -1, sep = "_")) %>% 
  filter(first == second)
  
  col_names_dup <- glue("{dupe_df$first}_{dupe_df$first}")

 .data <- .data %>%
  dplyr::select(-all_of(col_names_dup))
}

## Do it once, but then accidentally do the whole thing

# Have to create id only column data frame to bind back with this function at the end

lags_id_only <- train_nested_ema %>% 
  dplyr::select(-ema_data, -contains("yb"))

# Now the function

tic()
train_dtw_stats <-cdi_data_init %>% 
  dplyr::select(lifepak_id:response_no, c(bad, control:movement, sad),lifepak_id_int) %>% 
  filter(lifepak_id %in% train_nested_ema$lifepak_id) %>% 
  dplyr::select(-lifepak_id) %>% 
  group_by(lifepak_id_int) %>% 
  complete(response_no = 1:107) %>%
  dplyr::mutate(across(where(is.numeric), ~na_interpolation(.x, option = "spline")
  ),
  response_no = as.integer(response_no)) %>%
  ungroup() %>% 
  as_tsibble(key = lifepak_id_int, index = response_no) %>% 
  group_by(lifepak_id_int) %>% 
  tidy_imputation() %>% 
  dplyr::select(where(is.numeric)) %>% 
  ungroup() %>%
  as_tibble() %>% 
  dplyr::select(-response_no) %>% 
  group_split(lifepak_id_int) %>% 
  map(creating_dtw_distances) %>%
  map_dfr(pivoting_dtw_results_wider) %>% 
  bind_cols(lags_id_only) %>% 
  ungroup() %>% 
  exclude_dtw_same_var_features() %>% 
  relocate(lifepak_id, everything()) %>% 
  dplyr::select(-starts_with("yb_dep_diff"))
toc()

```

```{r running all preprocessing once}

## Merge tsfresh with dynamic time warp features

tic()
train_data_preprocess <- ts_fresh_id %>% 
  left_join(train_dtw_stats, by = "lifepak_id") %>%
  mutate(across(everything(), ~ifelse(is.nan(.x), NA, .x))) %>% 
  mutate(across(everything(), ~ifelse(is.infinite(.x), NA, .x))) %>% 
  bind_cols(train_outcome_wide)
toc()

## Using prep and bake with recipes to preprocess data (Getting rid of near zero variance features, normalizing all variables (necessary preprocessing for the neural network autoencoder), and using K nearest neighbors to impute missing predictor data

## Maybe add a Box_Cox Step? Should visualize skew/non skew of predictors before and after to check

rec_ema <- 
  recipes::recipe(yb_dep_diff~ ., data = train_data_preprocess) %>% 
  update_role(lifepak_id, new_role = "id") %>% 
  step_nzv(all_predictors()) %>%
  step_normalize(all_predictors()) %>%
  step_impute_knn(all_predictors())

tic()
set.seed(33)
train_imp_nzv <- rec_ema %>% 
  prep(verbose = TRUE) %>% 
  bake(new_data = train_data_preprocess)
toc()

```

```{r creating recipe for running a predictive model with pca generated features}

## Recipes don't like list columns, but I may be able to hack around it https://github.com/tidymodels/recipes/issues/402

rec_ema_pca <- 
  recipes::recipe(yb_dep_diff ~ ., data = train_imp_nzv) %>% 
  update_role(lifepak_id, new_role = "id") %>% 
  step_pca(all_predictors(), threshold = 0.95)

## Could also work on making threshold tunable

```

```{r creating recipe for running a predictive model with the raw features}

## Recipes don't like list columns, but I may be able to hack around it https://github.com/tidymodels/recipes/issues/402

rec_ema_raw <- 
  recipes::recipe(yb_dep_diff ~ ., data = train_imp_nzv) %>% 
  update_role(lifepak_id, new_role = "id")

```

```{r creating a recipe for running a predictive model with the umap features}

## This is supervised, non-linear dimensionality reduction without needing to use an autoencoder

# rec_ema_umap <- 
#   recipes::recipe(dep_deteriorate ~ ., data = train_data_with_summ_stats_imp_nzv) %>% 
#   update_role(id, new_role = "id") %>% 
#   step_umap(all_predictors(), outcome = vars(dep_deteriorate), num_comp = 5)

```


```{r testing whether the preliminary recipe works within a workflow}

# Create a random forest model

rf_mod <- rand_forest() %>% 
  set_engine("ranger") %>% 
  set_mode("regression")

elnet_mod <- linear_reg(penalty = 0.99, mixture = 0.99) %>% 
  set_engine("glmnet")

xg_mod <- boost_tree() %>% 
  set_engine("xgboost") %>% 
  set_mode("regression")

# Create a list of preprocessing recipes

base_model_rec_list <- list(rec_ema_pca, rec_ema_raw)

# Create a list of models

base_model_mod_list <- list(rf_mod, elnet_mod, xg_mod)

# Create data frame that matches all possible combinations of recipes and models

rec_mods_df <- expand_grid(base_model_rec_list, base_model_mod_list) 

# Combining each recipe into a tidymodels workflows using a map function

base_model_wfs <- map2(rec_mods_df$base_model_rec_list, rec_mods_df$base_model_mod_list, ~{
  
  ema_autoencoder_rf_wf <- workflow() %>% 
  add_recipe(.x) %>% 
  add_model(.y)
}
)

# Create as list of dataframes we'll be using to fit these models

base_model_data_list <- list(train_imp_nzv, train_imp_nzv, train_imp_nzv, train_imp_nzv, train_imp_nzv, train_imp_nzv)

# Fitting each model once to make sure they run, and they do

base_model_one_time_fit <- map2(base_model_wfs, base_model_data_list, ~{
  
tic()
ema_rf_wf_fit <- fit(.x, data = .y)
toc()
ema_rf_wf_fit
  
})

```

```{r}

## Fit resamples is having a hard time running these models (no errors but just continuing trying to compute for long periods of time without actually completing the computation). Might have something to do with this issue: https://github.com/tidymodels/tune/issues/206

base_model_fit_all_rs <- map2(base_model_wfs, base_model_data_list, ~{
  
registerDoMC(cores = 7)

set.seed(33)
folds_ema_pred <- vfold_cv(.y, v = 4, repeats = 10, strata = yb_dep_diff)

## Run the CV models here
keep_pred <- control_resamples(save_pred = TRUE)
tic()
set.seed(33)
rf_fit_rs <- 
  .x %>% 
  fit_resamples(folds_ema_pred, control = keep_pred)
toc()
rf_fit_rs

} 
)

## Get metrics here

base_model_metrics_all_rs <- map(base_model_fit_all_rs, ~{
  
  rsq_metric <- .x %>% 
  collect_metrics(summarize = TRUE)

}) %>% 
  print()

## Saving the predictions/actual differences here

base_model_preds_all_rs <- map(base_model_fit_all_rs, ~{
  
  rsq_metric <- .x %>% 
  collect_predictions(summarize = TRUE)

}) %>% 
  print()

# base_model_plots_all_rs <- map(base_model_fit_all_rs, ~{
#   
#   auc <- .x %>% 
#   collect_predictions(summarize = TRUE) %>% 
#   roc_curve(truth = dep_deteriorate, .estimate = .pred_TRUE) %>% 
#   autoplot()
# 
# }) %>% 
#   print()

```

# Plotting True Scores vs Predictions, Ideally Want Them All on the Same Line

```{r}

map(base_model_preds_all_rs, ~{
  .x %>% 
  ggplot(aes(x = yb_dep_diff, y = .pred)) +
  geom_point() +
  geom_abline(col = "dodgerblue1")
}) 
  

```

# Can We Match the Accuracy of These Models with Data Just From Baseline?

## Clean Into Training Data

```{r}

# Let's take the training data and bring back the baseline variables

pre_for_mod <- train_nested_ema %>% 
  ungroup() %>% 
  select(-ema_data, -yb_dep_diff) %>% 
  left_join(pre_post_data, by = c("lifepak_id" = "yb_life_pak_id")) %>% 
  select(lifepak_id, yb_dep_diff, contains("mean")) %>% 
  select(lifepak_id, yb_dep_diff, contains("yb"), -mean_yb_cdi, -mean_yb_idas) %>% 
  print()


```
## Create Modeling Workflow

```{r}

# Create preprocessing recipe

rec_pre <- 
  recipes::recipe(yb_dep_diff~ ., data = pre_for_mod) %>% 
  update_role(lifepak_id, new_role = "id") %>% 
  step_nzv(all_predictors()) %>%
  step_normalize(all_predictors()) %>%
  step_impute_knn(all_predictors())

# Test that doing the preprocessing won't crash anything

tic()
set.seed(33)
train_imp_nzv <- rec_pre %>% 
  prep(verbose = TRUE) %>% 
  bake(new_data = pre_for_mod)
toc()

pre_rf_wf <- workflow() %>% 
  add_recipe(rec_pre) %>% 
  add_model(elnet_mod)

```

## Run Model Over Resamples

```{r}

registerDoMC(cores = 7)

set.seed(33)
folds_pre_pred <- vfold_cv(pre_for_mod, v = 4, repeats = 10, strata = yb_dep_diff)

## Run the CV models here

# Keep the predictions for plotting
keep_pred <- control_resamples(save_pred = TRUE)

tic()
set.seed(33)
pre_rf_rs <- 
  pre_rf_wf %>% 
  fit_resamples(folds_pre_pred, control = keep_pred)
toc()

pre_rf_rs %>% 
  collect_metrics(summarize = TRUE)

```

## Can We Reduce the Model Even Further?

```{r}

rec_pre_red <- 
  recipes::recipe(yb_dep_diff~ lifepak_id + mean_yb_bads + mean_yb_bhs, data = pre_for_mod) %>% 
  update_role(lifepak_id, new_role = "id") %>% 
  step_nzv(all_predictors()) %>%
  step_normalize(all_predictors()) %>%
  step_impute_knn(all_predictors())

pre_red_wf <- workflow() %>% 
  add_recipe(rec_pre_red) %>% 
  add_model(elnet_mod)

## Run the CV models here

tic()
set.seed(33)
pre_red_rs <- 
  pre_red_wf %>% 
  fit_resamples(folds_pre_pred, control = keep_pred)
toc()

pre_red_rs %>% 
  collect_metrics(summarize = TRUE)

```

